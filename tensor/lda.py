"""
和nlp中的LDA区分开来， 其LDA是隐含狄利克雷分布（Latent Dirichlet Allocation，简称LDA），是一种处理文档的主题模型
-----
LDA是一种监督学习的降维技术，也就是说它的数据集的每个样本是有类别输出的。这点和PCA不同。PCA是不考虑样本类别输出的无监督降维技术。
LDA的思想可以用一句话概括，就是“投影后类内方差最小，类间方差最大”
将数据在低维度上进行投影，投影后希望每一种类别数据的投影点尽可能的接近，而不同类别的数据的类别中心之间的距离尽可能的大
与PCA不同，更关心分类而不是方差
"""
